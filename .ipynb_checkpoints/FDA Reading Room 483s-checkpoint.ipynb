{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA Reading Room 483 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "print(\"Script last ran on {}\".format(date.today().strftime(\"%m/%d/%Y\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import lxml\n",
    "import html5lib \n",
    "from bs4 import BeautifulSoup\n",
    "import janitor\n",
    "import tempfile\n",
    "\n",
    "# selenium functions\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys #allow  you to enter keystrokes into fields\n",
    "from selenium.webdriver.support.ui import Select #allow you to select a dropdown item\n",
    "from selenium.webdriver.support.ui import WebDriverWait #lets you modify a field before proceeding\n",
    "from selenium.common.exceptions import NoSuchElementException "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scrape Data Table and List of URLs to Form 483s from URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Establishment Types to Filter By__  \n",
    "Outsourcing Facility, Producer of Sterile and Non Sterile Drug Products, Producer of Sterile Drug Products, Producer of Non Sterile Drug Products, Manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fda.gov/about-fda/office-regulatory-affairs/ora-foia-electronic-reading-room'\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "table class = lcsd-datatable--ora-foia-reading table table-bordered dataTable no footer dtr-inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize the filter box to select only 483s (value = 0)\n",
    "select = Select(driver.find_element_by_css_selector('#lcds-datatable-filter--record-filter'))\n",
    "select.select_by_value('0')\n",
    "\n",
    "# get the table headers\n",
    "## read the datatable of page 1 for the sake of retrieving headers\n",
    "datatable_xpath = '//*[@id=\"DataTables_Table_0\"]'\n",
    "records = driver.find_element_by_xpath(datatable_xpath)\n",
    "records_innerhtml = records.get_attribute('innerHTML')\n",
    "soup = BeautifulSoup(records_innerhtml, 'html.parser')\n",
    "trs = soup.findAll('tr')\n",
    "headers = []\n",
    "for th in trs[0].findAll('th'):\n",
    "    headers.append(th.text)\n",
    "headers\n",
    "\n",
    "# scrape all rows in each page of the paginated datatable\n",
    "final_page = int(driver.find_element_by_xpath('//*[@id=\"DataTables_Table_0_paginate\"]/ul/li[8]').text)\n",
    "rows = []\n",
    "for page in range(1, final_page + 1):\n",
    "    \n",
    "    datatable_xpath = '//*[@id=\"DataTables_Table_0\"]'\n",
    "    records = driver.find_element_by_xpath(datatable_xpath)\n",
    "    records_innerhtml = records.get_attribute('innerHTML')\n",
    "    soup = BeautifulSoup(records_innerhtml, 'html.parser')\n",
    "    trs = soup.findAll('tr')\n",
    "    \n",
    "    for i in range(1, len(trs)):\n",
    "        tds = []\n",
    "        #page_rows = []\n",
    "        for td in trs[i].findAll('td'):\n",
    "            a = td.findAll('a')\n",
    "            spans = td.findAll('span')\n",
    "            inputs = td.findAll('input')\n",
    "            ret = \"\"\n",
    "            if len(a) != 0 or len(spans) != 0 or len(inputs) != 0:\n",
    "                if len(a) != 0:\n",
    "                    for link in a:\n",
    "                        ret += link.text + ' - '+link['href']\n",
    "                if len(spans) != 0:\n",
    "                    for span in spans:\n",
    "                        ret += span.text + ' - '+span['title']\n",
    "                if len(inputs) != 0:\n",
    "                    for inp in inputs:\n",
    "                        if inp.has_attr('value'):\n",
    "                            if inp.has_attr('type'):\n",
    "                                if inp['type'] == 'hidden':\n",
    "                                    ret += inp['value']\n",
    "            else: \n",
    "                ret = td.text if td.text != '' and td.text != '\\n' else \"NaN\"\n",
    "            tds.append(ret)\n",
    "        rows.append(tds)\n",
    "        \n",
    "    driver.find_element_by_xpath('//*[@id=\"DataTables_Table_0_next\"]/a').click()\n",
    "\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rows, columns = headers)\n",
    "df[['Record Type', 'HREF']] = df['Record Type'].str.split(' - ', 1, expand = True)\n",
    "df = df.clean_names()\n",
    "df['pdf_url'] = 'https://www.fda.gov' + df['href']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df.groupby('establishment_type').size().reset_index(name = 'count').sort_values(by = 'count', ascending = False).establishment_type)\n",
    "relavent_establishment_types = ['Producer of Sterile Drug Products', 'Outsourcing Facility', 'Manufacturer', 'Drug Manufacturer',\n",
    "                               'Compounding Pharmacy', 'Producer of Non Sterile Drug Products', 'Sterile Drug Manufacturer', \n",
    "                               'Pharmaceutical Manufacturer', 'Human Drug Manufacturer', 'Biological Drug Manufacturer', \n",
    "                               'Active Pharmaceutical Ingredient Manufacturer', 'Manufacturer and Repacker', \n",
    "                               'Active Pharmaceutical Ingredient & Finished Dosage Manufacturer', 'Biotech API Manufacturer',\n",
    "                               'Finished Pharmaceutical Manufacturer']\n",
    "df2 = df[df['establishment_type'].isin(relavent_establishment_types)].reset_index()\n",
    "df2['record_date'] = pd.to_datetime(df2['record_date'])\n",
    "df2['publish_date'] = pd.to_datetime(df2['publish_date'])\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Read each 483 PDF through an OCR machine into notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_urls = list(df2.pdf_url)\n",
    "test_pdf = df2.pdf_url[0]\n",
    "#test_href = df2.href[0]\n",
    "record_reference = str(df2.company_name[0]) + str(df2.record_date[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(test_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pdf2image \n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "pages = convert_from_path(test_pdf, 300,\n",
    "                         output_file = str(record_reference + \" - Page \" + str(i) + \" of \" + str(len(pages)) + \".jpg\"),\n",
    "                         output_folder = \"./temp483pdfs\")\n",
    "i = 1\n",
    "for page in pages:\n",
    "    image_name = str(record_reference + \" - Page \" + str(i) + \" of \" + str(len(pages)) + \".jpg\")\n",
    "    page.save(\"/temp483pdfs/\" + image_name, \"JPEG\")\n",
    "    i = i+1\n",
    "\n",
    "#with tempfile.TemporaryDirectory() as path:\n",
    "#    images_from_path = convert_from_path(test_pdf, 300, output_folder = path)\n",
    "#    print(\"images exported\")\n",
    "#    # do something else\n",
    "    \n",
    "#pdf_images_tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempfile.TemporaryDirectory().cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tidy each document into a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Perform Topic Modeling on Most Recent 1 Year of Drug Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Useful Links__  \n",
    "https://medium.com/@sarfrazarshad/scraping-dynamically-created-tables-196b7cbe6c84  \n",
    "https://stackoverflow.com/questions/56757261/extract-href-using-pandas-read-html/56757977  \n",
    "https://stackoverflow.com/questions/60757571/python-pandas-parse-html-table-to-get-hidden-values-and-links  \n",
    "https://stackoverflow.com/questions/51092362/selenium-clicking-to-next-page-until-on-last-page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
